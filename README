Quick Start
---

```bash
# HDFS换作任意日志，在results下面生成相应文件夹和结果
python pipeline.py -i data/HDFS.log -t HDFS -o results/
  -i input rawlog
  -t name of logs
  -o output path

# do experiments for log2vec
python log2vec.py -i results -t HDFS
  -i input path
  -t name of logs
```


File Descriptions
---

#### preprocessing.py

```sh
#Filter variables in the logs BGL.log替换为相应日志文件，后命令文件名相应更改
python code/preprocessing.py -rawlog ./data/BGL.log

  -rawlog：raw logs
```

### Antonyms&Synonyms Extraction
```sh
#Extract antonyms and synonyms 
python code/get_syn_ant.py -logs ./data/BGL_without_variables.log -ant_file ./middle/ants.txt -syn_file ./middle/syns.txt

  -logs: logs
  -ant_file: antonyms
  -syn_file: synonyms
```

### Relation Triple Extraction

```sh
python code/get_triplet.py data/BGL_without_variables.log middle/bgl_triplet.txt

  data/BGL_without_variables.log: logs
  middle/bgl_triples.txt: triples
```

```sh
#If -s is added, temporary saving will be enabled. By default, every 10000 pieces will be saved, named "temp\_" + output\_file
python code/get_triplet.py input_file output_file -s
```

```sh
#If another parameter is added after -s, the number of bars saved per time is modified
python code/get_triplet.py input_file output_file -s 50000 
```


### Semantic Word Embedding

```shell
#Convert log file to single line for training
python code/getTempLogs.py -input data/BGL_without_variables.log -output middle/BGL_without_variables_for_training.log
```

```shell
cd ./LRWE/src/ 

make #make before you run
#The input file for training is the file obtained in the previous step
#更改部分，每个文件增加一层父级目录 ../
./lrcwe -train ../../../middle/BGL_without_variables_for_training.log  -synonym ../../../middle/syns.txt  -antonym ../../../middle/ants.txt -output ../../../middle/bgl_words.model -save-vocab ../../../middle/bgl.vocab -belta-rel 0.8 - alpha-rel 0.01  -alpha-ant 0.3 -size 32 -min-count 1 -triplet ../../../middle/bgl_triplet.txt
```


### Handle OOV Words

```shell
#Read the original vector file
python code/mimick/make_dataset.py --vectors middle/bgl_words.model --w2v-format --output middle/bgl_words.pkl

  --vectors：Results of w2v, the first row is the number of rows and dimensions (can be omitted), the format of each subsequent row is word + word vector: word d1 d2... d32
```


```shell
#Train the new embedding according to oov
#testvocab.txt为人工添加的日志中出现的新词汇，用于训练
python code/mimick/model.py --dataset middle/bgl_words.pkl  --vocab middle/testvocab.txt --output middle/oov.vector

  --dataset：Output of the first step
  --vocab：New words, you can write multiple words in batches, one word per line
  --output：Embedding file for new words
```

### Generate vector for logs 
#每个文件去掉一个当前目录 ./
```shell
python code/Log2Vec.py -logs data/BGL_without_variables.log -word_model middle/bgl_words.model -log_vector_file middle/bgl_log.vector -dimension 32
```



This code was completed by Weibin Meng, Yuheng Huang and Bingjin Chen in cooperation.

